{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bef1f23-03cf-4c0c-b233-2c997052327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/16 23:10:37 WARN Utils: Your hostname, bemas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.194.166.221 instead (on interface en0)\n",
      "24/04/16 23:10:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/16 23:10:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import time  \n",
    "import pyspark  \n",
    "from pyspark.sql import SparkSession  \n",
    "spark = SparkSession.builder.appName('recommendation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad78ce04-bc5a-49c6-9385-ff300cda86f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "|     1|    163|   5.0|964983650|\n",
      "|     1|    216|   5.0|964981208|\n",
      "|     1|    223|   3.0|964980985|\n",
      "|     1|    231|   5.0|964981179|\n",
      "|     1|    235|   4.0|964980908|\n",
      "|     1|    260|   5.0|964981680|\n",
      "|     1|    296|   3.0|964982967|\n",
      "|     1|    316|   3.0|964982310|\n",
      "|     1|    333|   5.0|964981179|\n",
      "|     1|    349|   4.0|964982563|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies = spark.read.load(\"sparkdata/movies.csv\", format='csv', header = True)\n",
    "ratings = spark.read.load('sparkdata/ratings.csv', format='csv', header = True)\n",
    "links = spark.read.load(\"sparkdata/links.csv\", format='csv', header = True)\n",
    "tags = spark.read.load(\"sparkdata/tags.csv\", format='csv', header = True)\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd9d52a-9fd3-4283-a54b-8becbe62fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the schema to understand the data types of features\n",
    "ratings = ratings.select(\"userId\", \"movieId\", \"rating\")\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa5290c-c484-406d-aad2-8f163ad65345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the data type to integer and float\n",
    "df = ratings.withColumn('userId', ratings['userId'].cast('int')).\\\n",
    "withColumn('movieId', ratings['movieId'].cast('int')).withColumn('rating', ratings['rating'].cast('float'))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac9371b-d1b3-4a5a-b803-5ad91a1fb079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ratings in each set: 60435, 20052, 20349\n"
     ]
    }
   ],
   "source": [
    "# split the data into train, validation and test sets\n",
    "train, validation, test = df.randomSplit([0.6,0.2,0.2], seed = 0)\n",
    "print(\"The number of ratings in each set: {}, {}, {}\".format(train.count(), validation.count(), test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbcb1b04-8658-4a53-8d66-73c67b9b1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sqrt\n",
    "def RMSE(predictions):\n",
    "    squared_diff = predictions.withColumn(\"squared_diff\", pow(col(\"rating\") - col(\"prediction\"), 2))\n",
    "    mse = squared_diff.selectExpr(\"mean(squared_diff) as mse\").first().mse\n",
    "    return mse ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e8ff60-8f9e-446b-b735-15c5e7fb9757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the model using ALS algorithm and find the right hyperparameters using Grid Search\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "def GridSearch(train, valid, num_iterations, reg_param, n_factors):\n",
    "    min_rmse = float('inf')\n",
    "    best_n = -1\n",
    "    best_reg = 0\n",
    "    best_model = None\n",
    "    # run Grid Search for all the parameter defined in the range in a loop\n",
    "    for n in n_factors:\n",
    "        for reg in reg_param:\n",
    "            als = ALS(rank = n, \n",
    "                      maxIter = num_iterations, \n",
    "                      seed = 0, \n",
    "                      regParam = reg,\n",
    "                      userCol=\"userId\", \n",
    "                      itemCol=\"movieId\", \n",
    "                      ratingCol=\"rating\", \n",
    "                      coldStartStrategy=\"drop\")            \n",
    "            model = als.fit(train)\n",
    "            predictions = model.transform(valid)\n",
    "            rmse = RMSE(predictions)     \n",
    "            print('{} latent factors and regularization = {}: validation RMSE is {}'.format(n, reg, rmse))\n",
    "            # track the best model using RMSE\n",
    "            if rmse < min_rmse:\n",
    "                min_rmse = rmse\n",
    "                best_n = n\n",
    "                best_reg = reg\n",
    "                best_model = model\n",
    "                \n",
    "    pred = best_model.transform(train)\n",
    "    train_rmse = RMSE(pred)\n",
    "    # best model and its metrics\n",
    "    print('\\nThe best model has {} latent factors and regularization = {}:'.format(best_n, best_reg))\n",
    "    print('traning RMSE is {}; validation RMSE is {}'.format(train_rmse, min_rmse))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5135ec-9917-4e1c-a1e6-12b59f2d3945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/16 23:10:56 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/04/16 23:10:56 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 latent factors and regularization = 0.05: validation RMSE is 0.9774929328788823\n",
      "6 latent factors and regularization = 0.1: validation RMSE is 0.9129091223429058\n",
      "6 latent factors and regularization = 0.2: validation RMSE is 0.8951553382560972\n",
      "6 latent factors and regularization = 0.4: validation RMSE is 0.9694803178313401\n",
      "6 latent factors and regularization = 0.8: validation RMSE is 1.1934058854574956\n",
      "8 latent factors and regularization = 0.05: validation RMSE is 0.991145449065857\n",
      "8 latent factors and regularization = 0.1: validation RMSE is 0.9168968752992065\n",
      "8 latent factors and regularization = 0.2: validation RMSE is 0.8984989590130781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1030:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 latent factors and regularization = 0.4: validation RMSE is 0.970257089065676\n",
      "8 latent factors and regularization = 0.8: validation RMSE is 1.1934001722789012\n",
      "10 latent factors and regularization = 0.05: validation RMSE is 0.9978579799721213\n",
      "10 latent factors and regularization = 0.1: validation RMSE is 0.9176672173294838\n",
      "10 latent factors and regularization = 0.2: validation RMSE is 0.89872811595771\n",
      "10 latent factors and regularization = 0.4: validation RMSE is 0.9695217458657989\n",
      "10 latent factors and regularization = 0.8: validation RMSE is 1.1934037198726448\n",
      "12 latent factors and regularization = 0.05: validation RMSE is 1.0053856065363034\n",
      "12 latent factors and regularization = 0.1: validation RMSE is 0.9177483821613751\n",
      "12 latent factors and regularization = 0.2: validation RMSE is 0.9000614069040118\n",
      "12 latent factors and regularization = 0.4: validation RMSE is 0.9701108570324755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 latent factors and regularization = 0.8: validation RMSE is 1.193400724202843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2320:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best model has 6 latent factors and regularization = 0.2:\n",
      "traning RMSE is 0.6876113846732682; validation RMSE is 0.8951553382560972\n",
      "Total Runtime: 162.54 seconds\n"
     ]
    }
   ],
   "source": [
    "# build the model using different ranges for Grid Search\n",
    "from pyspark.sql.functions import col, sqrt\n",
    "num_iterations = 10\n",
    "ranks = [6, 8, 10, 12]\n",
    "reg_params = [0.05, 0.1, 0.2, 0.4, 0.8]\n",
    "\n",
    "start_time = time.time()\n",
    "final_model = GridSearch(train, validation, num_iterations, reg_params, ranks)\n",
    "print('Total Runtime: {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "028d3bc1-4503-4d0f-ab5c-66c36a58296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing RMSE is 0.8959197572737135\n"
     ]
    }
   ],
   "source": [
    "pred_test = final_model.transform(test)\n",
    "print('The testing RMSE is ' + str(RMSE(pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d74ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|movieId|userId|\n",
      "+-------+------+\n",
      "|    543|    12|\n",
      "|   1357|    12|\n",
      "|   2485|    12|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_user = test.filter(test['userId']==12).select(['movieId','userId'])\n",
    "single_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc4d1580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+--------------------+--------------------+\n",
      "|movieId|userId|movieId|               title|              genres|\n",
      "+-------+------+-------+--------------------+--------------------+\n",
      "|    543|    12|    543|So I Married an A...|Comedy|Romance|Th...|\n",
      "|   1357|    12|   1357|        Shine (1996)|       Drama|Romance|\n",
      "|   2485|    12|   2485|She's All That (1...|      Comedy|Romance|\n",
      "+-------+------+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_user.join(movies, single_user.movieId == movies.movieId, 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f00a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2439:>                                                       (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|movieId|userId|prediction|\n",
      "+-------+------+----------+\n",
      "|   1357|    12|  5.015935|\n",
      "|    543|    12| 3.6550279|\n",
      "|   2485|    12| 3.4955368|\n",
      "+-------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reccomendations = final_model.transform(single_user)\n",
    "reccomendations.orderBy('prediction',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a81544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+-------+--------------------+--------------------+\n",
      "|movieId|userId|prediction|movieId|               title|              genres|\n",
      "+-------+------+----------+-------+--------------------+--------------------+\n",
      "|    543|    12| 3.6550279|    543|So I Married an A...|Comedy|Romance|Th...|\n",
      "|   1357|    12|  5.015935|   1357|        Shine (1996)|       Drama|Romance|\n",
      "|   2485|    12| 3.4955368|   2485|She's All That (1...|      Comedy|Romance|\n",
      "+-------+------+----------+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reccomendations.join(movies, reccomendations.movieId == movies.movieId, 'inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db25de07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies liked by user with ID 12\n",
      "+-------+--------------------+------+\n",
      "|movieId|               title|rating|\n",
      "+-------+--------------------+------+\n",
      "|    543|So I Married an A...|   3.5|\n",
      "|   1357|        Shine (1996)|   5.0|\n",
      "|   2485|She's All That (1...|   5.0|\n",
      "+-------+--------------------+------+\n",
      "\n",
      "Recommended movies for user with ID 12\n",
      "+-------+--------------------+----------+\n",
      "|movieId|               title|prediction|\n",
      "+-------+--------------------+----------+\n",
      "|  67618|Strictly Sexual (...|  6.166763|\n",
      "|   3379| On the Beach (1959)| 6.1177487|\n",
      "|   5867|        Thief (1981)| 5.9761686|\n",
      "|  42730|   Glory Road (2006)| 5.9761686|\n",
      "|   4535|Man from Snowy Ri...| 5.9761686|\n",
      "|   7121|   Adam's Rib (1949)|  5.967025|\n",
      "|  60943| Frozen River (2008)|  5.941128|\n",
      "|  33649|  Saving Face (2004)|  5.935265|\n",
      "|  25906|Mr. Skeffington (...| 5.9273844|\n",
      "|  77846| 12 Angry Men (1997)| 5.9273844|\n",
      "|   3200|Last Detail, The ...|  5.890436|\n",
      "|   3567|   Bossa Nova (2000)| 5.8710847|\n",
      "|  94070|Best Exotic Marig...|  5.857238|\n",
      "|   4789|Phantom of the Pa...| 5.8511386|\n",
      "|   3086|Babes in Toyland ...|  5.848856|\n",
      "| 138966|Nasu: Summer in A...|  5.843027|\n",
      "|  26928|Summer's Tale, A ...|  5.843027|\n",
      "|   3819|      Tampopo (1985)|  5.843027|\n",
      "|  84273|Zeitgeist: Moving...|  5.843027|\n",
      "| 184245|De platte jungle ...|  5.843027|\n",
      "+-------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "# select a single user from the test set\n",
    "user_id = 12\n",
    "single_user_ratings = test.filter(test['userId'] == user_id).select(['movieId', 'userId', 'rating'])\n",
    "\n",
    "# display the movies the user has liked\n",
    "print(\"Movies liked by user with ID\", user_id)\n",
    "single_user_ratings.join(movies, 'movieId').select('movieId', 'title', 'rating').show()\n",
    "\n",
    "# generate recommendations for the user\n",
    "all_movies = df.select('movieId').distinct()\n",
    "user_movies = single_user_ratings.select('movieId').distinct()\n",
    "movies_to_recommend = all_movies.subtract(user_movies)\n",
    "\n",
    "# predict ratings for movies the user has not rated yet\n",
    "recommendations = final_model.transform(movies_to_recommend.withColumn('userId', lit(user_id)))\n",
    "\n",
    "# filter out the movies that the user has already rated or seen (this filters out the movies that the user has not liked as well)\n",
    "recommendations = recommendations.filter(col('prediction') > 0)\n",
    "\n",
    "# display the recommendations with movie names\n",
    "print(\"Recommended movies for user with ID\", user_id)\n",
    "recommended_movies = recommendations.join(movies, 'movieId').select('movieId', 'title', 'prediction')\n",
    "\n",
    "# Sort recommended movies by prediction in descending order\n",
    "ordered_recommendations = recommended_movies.orderBy(col('prediction').desc())\n",
    "\n",
    "# Display the ordered recommendations\n",
    "ordered_recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f3264ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter movie names (separated by commas), each followed by its release year (in parentheses): Spider-Man (2002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|               title|\n",
      "+-------+--------------------+\n",
      "|   3086|Babes in Toyland ...|\n",
      "|   3379| On the Beach (1959)|\n",
      "|   3567|   Bossa Nova (2000)|\n",
      "|   5490|  The Big Bus (1976)|\n",
      "|   7121|   Adam's Rib (1949)|\n",
      "|  33649|  Saving Face (2004)|\n",
      "|  60943| Frozen River (2008)|\n",
      "|  67618|Strictly Sexual (...|\n",
      "| 132333|         Seve (2014)|\n",
      "| 147382|Doctor Who: Voyag...|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "def recommend_similar_movies():\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import lit\n",
    "\n",
    "    spark = SparkSession.builder.appName('recommendation').getOrCreate()\n",
    "\n",
    "    # User input for movie names\n",
    "    movie_list_input = input(\"Enter movie names (separated by commas), each followed by its release year (in parentheses): \")\n",
    "    movie_list = [movie.strip() for movie in movie_list_input.split(',')]\n",
    "\n",
    "    # Find movie IDs for the input movies\n",
    "    movie_ids = movies.select(\"movieId\", \"title\").filter(movies[\"title\"].isin(movie_list))\n",
    "\n",
    "    # Join the input movie IDs with ratings to find ratings for these movies\n",
    "    user_ratings = movie_ids.join(ratings, \"movieId\")\n",
    "\n",
    "    # Add a new column \"userId\" with a constant value (0) to represent the user\n",
    "    user_ratings = user_ratings.withColumn(\"userId\", lit(0))\n",
    "\n",
    "    # Ensure \"movieId\" column is of type Integer\n",
    "    user_ratings = user_ratings.withColumn(\"movieId\", user_ratings[\"movieId\"].cast(IntegerType()))\n",
    "\n",
    "    # Ensure \"rating\" column is of type Float\n",
    "    user_ratings = user_ratings.withColumn(\"rating\", user_ratings[\"rating\"].cast(FloatType()))\n",
    "\n",
    "    # Add missing columns to user_ratings to match the schema of train\n",
    "    user_ratings = user_ratings.select(\"userId\", \"movieId\", \"rating\")\n",
    "\n",
    "    # Add the user's ratings to the training data\n",
    "    user_data = train.union(user_ratings)\n",
    "\n",
    "    # Train the model again with the updated training data\n",
    "    updated_model = ALS(rank=final_model.rank, maxIter=final_model._java_obj.parent().getMaxIter(),\n",
    "                        seed=final_model._java_obj.parent().getSeed(),\n",
    "                        regParam=final_model._java_obj.parent().getRegParam(),\n",
    "                        userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "                        coldStartStrategy=\"drop\").fit(user_data)\n",
    "\n",
    "    # Create DataFrame containing the movies rated by the user\n",
    "    user_movies_df = user_ratings.select(\"userId\", \"movieId\").distinct()\n",
    "\n",
    "    # Get recommendations for the user\n",
    "    recommendations = updated_model.recommendForUserSubset(user_movies_df, 10)\n",
    "\n",
    "    # Extract recommended movie IDs\n",
    "    recommended_movie_ids = [recommendation.movieId for recommendation in recommendations.select(\"recommendations\").collect()[0][0]]\n",
    "\n",
    "    # Fetch movie titles for recommended movie IDs\n",
    "    recommended_movies_titles = movies.select(\"movieId\", \"title\").filter(movies[\"movieId\"].isin(recommended_movie_ids))\n",
    "\n",
    "    # Display recommended movie titles\n",
    "    recommended_movies_titles.show()\n",
    "\n",
    "# Example usage:\n",
    "recommend_similar_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0052c509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName('recommendation').getOrCreate()\n",
    "\n",
    "# Assume you have 'movies' and 'ratings' DataFrames available\n",
    "\n",
    "def recommend_similar_movies(movie_list_input):\n",
    "    global spark\n",
    "    \n",
    "    # Find movie IDs for the input movies\n",
    "    movie_list = [movie.strip() for movie in movie_list_input.split(',')]\n",
    "    movie_ids = movies.select(\"movieId\", \"title\").filter(movies[\"title\"].isin(movie_list))\n",
    "\n",
    "    # Join the input movie IDs with ratings to find ratings for these movies\n",
    "    user_ratings = movie_ids.join(ratings, \"movieId\")\n",
    "\n",
    "    # Add a new column \"userId\" with a constant value (0) to represent the user\n",
    "    user_ratings = user_ratings.withColumn(\"userId\", lit(0))\n",
    "\n",
    "    # Ensure \"movieId\" column is of type Integer\n",
    "    user_ratings = user_ratings.withColumn(\"movieId\", user_ratings[\"movieId\"].cast(IntegerType()))\n",
    "\n",
    "    # Ensure \"rating\" column is of type Float\n",
    "    user_ratings = user_ratings.withColumn(\"rating\", user_ratings[\"rating\"].cast(FloatType()))\n",
    "\n",
    "    # Add missing columns to user_ratings to match the schema of train\n",
    "    user_ratings = user_ratings.select(\"userId\", \"movieId\", \"rating\")\n",
    "\n",
    "    # Add the user's ratings to the training data\n",
    "    user_data = train.union(user_ratings)\n",
    "\n",
    "    # Train the model again with the updated training data\n",
    "    updated_model = ALS(rank=final_model.rank, maxIter=final_model._java_obj.parent().getMaxIter(),\n",
    "                        seed=final_model._java_obj.parent().getSeed(),\n",
    "                        regParam=final_model._java_obj.parent().getRegParam(),\n",
    "                        userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "                        coldStartStrategy=\"drop\").fit(user_data)\n",
    "\n",
    "    # Create DataFrame containing the movies rated by the user\n",
    "    user_movies_df = user_ratings.select(\"userId\", \"movieId\").distinct()\n",
    "\n",
    "    # Get recommendations for the user\n",
    "    recommendations = updated_model.recommendForUserSubset(user_movies_df, 10)\n",
    "\n",
    "    # Extract recommended movie IDs\n",
    "    recommended_movie_ids = [recommendation.movieId for recommendation in recommendations.select(\"recommendations\").collect()[0][0]]\n",
    "\n",
    "    # Fetch movie titles for recommended movie IDs\n",
    "    recommended_movies_titles = movies.select(\"movieId\", \"title\").filter(movies[\"movieId\"].isin(recommended_movie_ids))\n",
    "\n",
    "    # Display recommended movie titles\n",
    "    recommended_movies = recommended_movies_titles.collect()\n",
    "    recommended_movie_titles = [movie.title for movie in recommended_movies]\n",
    "    return recommended_movie_titles\n",
    "\n",
    "def on_submit():\n",
    "    movie_list_input = entry.get()\n",
    "    if movie_list_input:\n",
    "        recommendations = recommend_similar_movies(movie_list_input)\n",
    "        if recommendations:\n",
    "            messagebox.showinfo(\"Recommendations\", \"\\n\".join(recommendations))\n",
    "        else:\n",
    "            messagebox.showwarning(\"No Recommendations\", \"No recommendations found for the provided movies.\")\n",
    "    else:\n",
    "        messagebox.showwarning(\"Empty Input\", \"Please enter at least one movie.\")\n",
    "\n",
    "# Create main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Movie Recommendation System\")\n",
    "\n",
    "# Create input label and entry\n",
    "label = ttk.Label(root, text=\"Enter movie names (separated by commas), each followed by its release year (in parentheses):\")\n",
    "label.pack(pady=10)\n",
    "\n",
    "entry = ttk.Entry(root, width=50)\n",
    "entry.pack(pady=5)\n",
    "\n",
    "# Create submit button\n",
    "submit_button = ttk.Button(root, text=\"Submit\", command=on_submit)\n",
    "submit_button.pack(pady=5)\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384b27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
